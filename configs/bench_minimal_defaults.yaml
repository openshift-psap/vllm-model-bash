#plain runs (no Nsight, no custom configs)
#global env propagation only
#separate model directories confirmed


bench:
  concurrencies: [1, 8]
  input_len: 512
  output_len: 128
  cc_mult: 10
  result_prefix: results
  collect_nsys: false
  profile: false
  study_dir: "Study_Minimal"
  env:
    HF_HOME: "/mnt/workspace"
    TORCH_CUDA_ARCH_LIST: "9.0"

models:
  - name: openai/gpt-oss-20b
    port: 8000
    params: "--max-model-len 8192 --max-num-seq 128"

  - name: openai/gpt-oss-120b
    port: 8001
    params: "--max-model-len 8192 --max-num-seq 256"
